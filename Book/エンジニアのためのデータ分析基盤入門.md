# エンジニアのためのデータ分析基盤入門

## 1. ［入門］データ分析基盤
* データの種類
    * 非構造データ：Excel, PDF
    * 半構造データ：CSV, JSON
    * 構造データ　：RDB
* データ分析基盤とは
    * 社内外のありとあらゆるデータが混ざり合うことで、さまざまな知見をデータから得ようという動きがあり、データ分析基盤の主な役割は、それらのデータから「パターン」や「関係」を知るためのサポートを行うことです。
* データ分析基盤が持つ役割
    * **データレイク**
        * ローデータ保管
        * 一時データの保存
        * データの受付口
    * **データウェアハウス**
        * 構造データ保管
        * 機密データの保存
    * **データマート**
        * 構造データ保管<br>
        ※データウェアハウスに比べ、より整備されたデータ
* 処理基盤/クラスターの変遷
    * 分散処理（Hadoop）
    * MPPDB
    * クラウド（Hadoop, Kubernetes, MPPDB）

    ※根底の仕組みなどは大きく変わらない
* データ分析に携わる人
    * データエンジニア
    * アナリティクスエンジニア
    * データサイエンティスト
    * BIエンジニア
    * データアナリスト

## 2. データエンジニアリングの基礎知識
* データ分析基盤の基本構造
    * **コレクティングレイヤー**（データを収集する）
        * ストリーミング　：絶え間なくデータを収集する
        * バッチ　　　　　：一定以上の塊のデータを収集する
        * プロビジョニング：ひとまず仮にデータを配置する
    * **プロセシングレイヤー**（収集したデータを処理する）
        * ETL（抽出、変換、転送）
            * バッチ処理　　　　：Apache Hive, Spark
            * ストリーミング処理：Apache Spark, Kafka
        * ELT（抽出、転送、変換）
            * ETLに台頭
        * データラングリング
            * データに対する付加価値をつける
        * 暗号化
        * データ品質計算/メタデータ計算
    * **ストレージレイヤー**（収集したデータを保存する）
        * マスターデータ管理
            * データ活用型のマスターデータ管理
                * 各システムにある独自のマスターデータとは別にデータ分析基盤の中に、独自のマスターデータを持つ
        * メタデータストア
            * メタデータの種類
                * ビジネスメタデータ　　　　：テーブル定義, ドメイン知識
                * テクニカルメタデータ　　　：ログデータや技術詳細, データ品質
                * オペレーショナルメタデータ：操作履歴
            * サービス
                * AWS Glue DataCatalog
        * データゾーン
            * ローゾーン
                * 集めたデータをそのまま保存
            * ゴールドゾーン
                * データマート
                * データウェアハウス
            * ステージングゾーン
                * イミュータブルなデータの提供
                    * 元データの保存
            * クォレンティーンゾーン
                * 機密情報を保持する隔離されたゾーン
            * テンポラリーゾーン
                * 一時的に利用できるようなゾーン
    * **アクセスレイヤー**（ユーザーと接点となる）
        * GUI
        * BIツール（SQL）
        * API
        * ストレージへの直接アクセス
        * メッセージキューに対するアクセス

## 3. データ分析基盤の管理＆構築
* セルフサービス
    * データ分析の需要からエンジニアがボトルネックになるケースが増えた
    * ユーザーごとに適切なインターフェースを提供する  
* SSoT
    * 避けるべきは個々のサービスで小さなデータ分析基盤を持つようなデータのサイロ化
    * フィジカルSSoT
        * 個々のサービスのデータを物理的に1ヶ所に集める仕組み
    * ロジカルSSoT
        * 1ヶ所に集めたように見せる
        * 管理が複雑になるが、ETLなどで1ヶ所に集める労力もなくなる
* データ管理デザインパターン
    * タグとゾーンを組み合わせる
        * 物理的なゾーンではデータの行き来にコストがかかる
        * 論理的なゾーンではタグを変更するだけでゾーンの切り替えが可能
    * GAパターン
        * 機密性の高いデータが存在する場合は、一度クォレンティーンゾーンへ格納後に、ローゾーンに移管するか判断を行う
    * プロビジョニングパターン
        * 必要な時にデータをテンポラリゾーンに配置し、データマート等のデータと掛け合わせてb分析を行う
    * システムによる自動チェック
        * Aパターンもプロビジョニングパターンも人が判断や実行を行うというボトルネックがある
        * データのチェックやデータの投入のチェックをシステムが行う
* データの管理とバックアップ
    * データの管理
        * ロケーション
        * パーティション
    * バックアップ
* データのアクセス制御
    * 制御の粒度
        * ゾーン
        * データベース
        * テーブル
        * カラム/レコード
* One Size Fits All問題
    * デカップリング
        * 計算リソースの最適化
        * ストレージレイヤーとプロセシングレイヤーのぶんり
        * コレクティングレイヤーやアクセスレイヤーの分離
* データのライフサイクルマネジメント
    * データの発生
    * データの成長
    * データの最後
        * サマリー化
        * データのアーカイブ
        * データの削除

## 4. データ分析基盤の技術スタック
* クラスター
* コレクティングレイヤー
* プロセシングレイヤー
* ワークフローエンジン
* ストレージレイヤー
    * フォーマット
        * 列指向フォーマット
        * 行指向フォーマット
    * 種類
        * Parquet
        * Avro
* アクセスレイヤー
    * アクセス制御

## 5. メタデータ管理
* 種類
    * ビジネスメタデータ　　　　：テーブルやデータベースの特性を示す
    * テクニカルメタデータ　　　：データに対する技術的詳細を示す
    * オペレーショナルメタデータ：システムの運用やデータの移動過程などで生成される
* 提供の価値
    * データ基盤に対する疑問点の解消につながる
    * データに対するドメイン知識のギャップを緩和できる
    * データを利用するシステムや人の動きを統一する
    * 非同期にデータを利用する状況を作る
    * アクセス権限に縛られずデータを見つけるヒントになる
* データプロファイリング
    * データの状態を知る
* データカタログ
* データアーキテクチャ

## 6. データマート＆データウェアハウスとデータ整備
* DIKWモデル
    * Data　　　：断片的なデータ
    * Information：分類されたデータ
    * Knowledge  ：知識
    * Wisdom 　 ：知恵
* データマートの役割
    * `Data`を`Information`にすること
* スキーマ設計
    * スタースキーマ
        * ファクトテーブル　　　：本体
        * ディメンションテーブル：付加情報（補足情報）
    * 非正規化
        * 読み込み効率（テーブル結合）を上げるため
        * 列指向フォーマットの進展による影響もあり
* データマートの生成サポート
    * セルフサービスモデル：各自データを利用したい人に自由に作成させるせる
    * サポート
        * インターフェースを複数用意
        * メタデータや仕組みを整備しておく
        * 中間テーブルの作成や、アドバイスなど
    * 中間テーブル
        * アクセスログを利用して頻繁に結合されるテーブルで中間テーブルを作成しておく
        * Viewによる中間テーブルの作成
    * データマートのプロパゲーション
        * データマートの作成や利用に関するルール
            * 定量的なデータを集める
                * アクセス頻度を確認
            * 事前のルール作り
                * データマート生成停止の条件を定める
            * メタデータの活用
                * 削除予定のデータマートにオペレーショナルメタデータをつけておく
                * 新規に作成されたデータマートを知る仕組み

## 7. データ品質管理
* データ品質管理の三原則
    1. 防ぐ/予防　　：40%
    2. 見つける/検知：40%
    3. 修正する/修理：20%
* データ品質の観点
    1. 正確性　　：データが実態を表しているかどうか
    2. 完全生　　：データが全部揃っているか
    3. 一貫性　　：データのフォーマットや値が一貫しているか
    4. 有効性　　：データが指定のフォーマットに沿っているか
    5. 適時性　　：データが最新でかつタイミングよくデータがあるべき場所に存在しているか
    6. ユニーク性：で０たの重複が存在せず、その値がただ1つの値を示しているか
* データの劣化
    * 原因
        1. データの往来
            * 通信要件：通信が途切れた場合など
            * データを転送時：転送の失敗など
        2. データの変換
            * ビッグデータシステムとスモールデータシステムの守備範囲の違い
            * データマートを含むETLによる変換
            * プロダクト連携時
        3. 時間の経過
            * 貨幣価値
            * 既に終了してしまったサービスのデータ
            * 当時は利用されていたがアクセスがなくなったデータ
        4. 人的要因
            * プログラムミス
            * 考慮漏れ
* データ品質テスト
    1. レベルの設定を行う
    2. テストの実施を行う
    3. 結果の可視化を行う
    4. 結果からの改善の手立てを打つ
* メタデータ品質
    * メタデータの名寄せ
    * 言語の認識合わせ
* データ品質を向上させる
    * データのリペア

## 8. データ分析基盤から始まるデータドリブン
* データドリブンのためのPDCA
    1. KPI/KGI/CSFを設定する
    2. 改善前のKPIに関する数値を取得する
    3. 改善する
    4. 改善後のKPIに関する数値を取得し、評価する
* データ分析基盤観点のKPI/KGI/CSF
    * クエリーのしやすさKGI
    * フリクションKGI
    * データマネジメントKGI
    * データエンゲージメントKGI
